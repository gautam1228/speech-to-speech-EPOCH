{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.signal import wiener\n",
    "from scipy.ndimage import convolve1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in videos_audios\\output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def video_to_audio(video_path, audio_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Extract audio from the video\n",
    "    audio_clip = video_clip.audio\n",
    "\n",
    "    # Write the audio file\n",
    "    audio_clip.write_audiofile(audio_path)\n",
    "\n",
    "    # Close the video clip\n",
    "    video_clip.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_file_path = \"videos_audios\\RIISE 2022 final video.mp4\"  # Replace with your video file path\n",
    "    audio_file_path = \"videos_audios\\output_audio.wav\"  # Replace with your desired audio file path\n",
    "\n",
    "    video_to_audio(video_file_path, audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_subtraction(audio_file, output_file, n_fft=2048, hop_length=512):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Estimate noise from the first few frames of audio\n",
    "    noise_frames = audio[:n_fft]\n",
    "    noise_mean = np.mean(np.abs(librosa.stft(noise_frames, n_fft=n_fft, hop_length=hop_length)), axis=1)\n",
    "\n",
    "    # Compute STFT (Short-Time Fourier Transform) for audio\n",
    "    stft_audio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # Compute power spectrum for audio\n",
    "    power_audio = np.abs(stft_audio)**2\n",
    "\n",
    "    # Perform spectral subtraction\n",
    "    power_clean = np.maximum(power_audio - noise_mean[:, np.newaxis], 0.0)\n",
    "\n",
    "    # Reconstruct audio signal\n",
    "    clean_audio = librosa.istft(np.sqrt(power_clean * np.exp(1j * np.angle(stft_audio))),\n",
    "                                hop_length=hop_length)\n",
    "\n",
    "    # Write cleaned audio to file\n",
    "    sf.write(output_file, clean_audio, sr)\n",
    "\n",
    "# Example usage\n",
    "spectral_subtraction(\"videos_audios\\output_final.wav\", \"videos_audios\\output_cleaned.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background_noise(audio_file, output_file, noise_level=50):\n",
    "    # Step 1: Load Audio File\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Step 2: Short-time Fourier Transform (STFT)\n",
    "    D = librosa.stft(y)\n",
    "\n",
    "    # Step 3: Spectral Subtraction\n",
    "    magnitude = np.abs(D)\n",
    "    power = magnitude ** 2\n",
    "    noise_power = np.median(power, axis=1) * noise_level\n",
    "    mask = np.where(power <= noise_power[:, np.newaxis], 0.0, 1.0)\n",
    "    D_cleaned = mask * D\n",
    "\n",
    "    # Step 4: Inverse Short-time Fourier Transform (ISTFT)\n",
    "    y_cleaned = librosa.istft(D_cleaned)\n",
    "\n",
    "    # Step 5: Save Cleaned Audio using scipy\n",
    "    wavfile.write(output_file, sr, np.int16(y_cleaned*32767))  # Scaling to 16-bit integer\n",
    "\n",
    "# Example usage\n",
    "remove_background_noise(\"videos_audios\\output_final.wav\", \"videos_audios\\output_cleaned_final.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_beats_and_events(audio_file, output_file, threshold=1, beat_duration=0.6):\n",
    "    # Step 1: Load Audio File\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Step 2: Detect Beats or Loud Events\n",
    "    # For simplicity, let's use amplitude thresholding\n",
    "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, backtrack=True, hop_length=512)\n",
    "\n",
    "    # Convert onset frames to time locations\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "\n",
    "    # Step 3: Attenuate or Remove Detected Sections\n",
    "    for onset_time in onset_times:\n",
    "        start_sample = librosa.time_to_samples(onset_time)\n",
    "        end_sample = start_sample + int(sr * beat_duration)\n",
    "\n",
    "        # Remove or attenuate the detected section (e.g., set amplitudes to zero)\n",
    "        y[start_sample:end_sample] = 0  # Replace with your desired modification\n",
    "\n",
    "    # Step 4: Save Cleaned Audio using scipy\n",
    "    wavfile.write(output_file, sr, y)\n",
    "\n",
    "# Example usage\n",
    "remove_beats_and_events(\"videos_audios\\output_cleaned2.wav\", \"videos_audios\\output_cleaned3.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
